{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shadow Detection for Mobile Robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab notebook\n",
    "pylab.rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "from IPython.display import YouTubeVideo as yt\n",
    "def YouTubeVideo(_id):\n",
    "    return yt(_id, width=800, height=450)\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "from shadow import _imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Recap of Project\n",
    "\n",
    "This project is about *shadow detection for mobile robots* - detecting shadows with an *active camera*. This is challenging because the majority of previous work revolves around using a background model to detect changed parts of a scene. This obviously can't work for active video!\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "The detection of shadows is possible by combining information about texture features (something that remains largely unchanged under shadow) with other information - including local maxima, smoothness, or other colourimetric features.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "* Capturing multiple datasets\n",
    "* Simple shadow detection with colour/brightness\n",
    "* Texture feature investigation\n",
    "* Clustering texture features into contiguous regions\n",
    "* Combining \n",
    "* Machine learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "### Static Camera (or \"easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = [imread(\"../data/static/%s/images/small-00044.png\" % (i))\n",
    "          for i in [\"bobbly-slabs\", \"bricks\", \"smooth-slabs\", \"tarmac\"]]  \n",
    "_imshow(2, False, *images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Camera (or \"slightly less easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = [imread(\"../data/active/%s/images/small-00044.png\" % (i))\n",
    "          for i in [\"grass-path\", \"seafront-gravel\", \"seafront-path\"]]  \n",
    "_imshow(2, False, *images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth\n",
    "\n",
    "The following video is an example of some of the initial techniques that I was using to generate ground truth. This involved using local brightness maxima and some morphological post-processing to reduce noise and fill holes (opening/closing). This is pretty much the point I'd reached at the time of the mid-project demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"j5PmcK6b4dQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So, for example, the ground truth looks like this...\n",
    "image = imread(\"../data/static/smooth-slabs/images/small-00052.png\")\n",
    "ground_truth = imread(\"../data/static/smooth-slabs//ground-truth/small-00052.png\")\n",
    "_imshow(1, False, image, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture\n",
    "\n",
    "### Choice of Texture Feature\n",
    "\n",
    "A large part of this project revolved around choosing texture features based on their shadow invariance. In the end, local binary patterns turned out to be the *best* texture feature - although, LBPs were chosen based on a combination of factors, rather than solely shadow invariance.\n",
    "\n",
    "### Flaws in Analytical Method\n",
    "\n",
    "The simplest way of comparing the shadow invariance of texture features seemed to be extracting two sets of features for an image pair - one image under shadow, and the other with no shadow - then using a simple metric for difference, such as mean squared error (essentially, Euclidean distance).\n",
    "\n",
    "However, as became clear during experimentation, different feature types can't necessarily be compared in this manner as their data structures can be completely different. A sparse data structure, (for example, from a GLCM - a mostly-empty array), may exhibit a *very low* mean squared error - whereas a more dense structure (for example, an LBP) may give a considerably different result.\n",
    "\n",
    "I would have changed this or investigated this more, given time.\n",
    "\n",
    "### Texture Feature Clustering\n",
    "\n",
    "K-means was the primary clustering technique used in this project. As well as having a particularly performant mini-batch implementation in `scikit-learn`, it was also the most straightforward algorithm to use - its only drawback was having to specify $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shadow\n",
    "\n",
    "image = io.imread(\"../data/static/bricks/images/small-00015.png\", as_grey=True)\n",
    "clusters = shadow.k_means_texture_cluster(image)\n",
    "\n",
    "_imshow(2, False, image, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notable Mention\n",
    "\n",
    "It's annoying to have to specify $k$ for each image, particularly on unknown image sequences. Online, unsupervised estimation of $k$ is a whole other project in itself, so I also tried DBSCAN for clustering (which is a clustering algorithm that does not have this requirement). DBSCAN essentially looks for areas of density separated by sparse areas. It was incredibly slow (almost unusable, actually), so it wasn't used in the end - but it was worth mentioning.\n",
    "\n",
    "### Testing Clustering Quality\n",
    "\n",
    "Because of the flawed analysis of shadow-invariant texture features, instead I evaluated how consistent texture clusters were under shadow. This simply involved applying a clustering algorithm to texture features from shadow-free/shadowed image pairs, and comparing the resultant clusters with various metrics (e.g. Adjusted Rand Index, Homogeneity, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Clustering-Based Shadow Detection\n",
    "\n",
    "### Without Variance Threshold\n",
    "\n",
    "Note that a considerable proportion of the input image is detected as shadow. These false positives are created due to considerable variations in brightness at a particularly fine scale - caused by the small gravel particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shadow\n",
    "\n",
    "image = io.imread(\"../data/static/tarmac/images/small-00170.png\", as_grey=True)\n",
    "ground_truth = io.imread(\"../data/static/tarmac/ground-truth/small-00170.png\", as_grey=True)\n",
    "shadow_pred = shadow.k_means_classifier(image)\n",
    "_imshow(1, False, image, shadow_pred, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Variance Threshold\n",
    "\n",
    "Note that the variance threshold suppresses all of the superfluous shadow detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shadow\n",
    "\n",
    "image = io.imread(\"../data/static/tarmac/images/small-00170.png\", as_grey=True)\n",
    "ground_truth = io.imread(\"../data/static/tarmac/ground-truth/small-00170.png\", as_grey=True)\n",
    "shadow_pred = shadow.k_means_variance_classifier(image)\n",
    "_imshow(1, True, image, shadow_pred, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Very close to the end of the project, there were one or two days spare - so it made sense to experiment with some machine learning techniques before time ran out. Two types were trialled - decision trees and random forests.\n",
    "\n",
    "### Decision Trees\n",
    "\n",
    "Decision trees were the most effective machine learning technique used in this project, mostly due to their extreme simplicity and excellent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"zBXaazf0vI8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forests\n",
    "\n",
    "Random forests yielded very similar output to decision trees, with a little less overfitting. They were a little more effective than decision trees (of the order of a few percent), but were incredibly resource-intensive - so were somewhat impractical. Nonetheless, here's a quick sample of some output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"GQUTqY1oths\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
